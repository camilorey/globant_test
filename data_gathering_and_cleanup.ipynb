{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "#to see progress bars\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First task: Download the Files from the Birmingham City Council Website \n",
    "\n",
    "In order to download *all* de Excel files from the Birmingham City Council datasets website, I created a 3-column Excel file containing containing the following columns: \n",
    "- *Año*: the year of the report\n",
    "- *Mes*: the month of the report\n",
    "- *Link*: The URL from which I can download the Excel File. \n",
    "\n",
    "This is to automate loading the Excel Files, without downloading them into my computer. I named this file **file_sources.xls**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_df = pd.read_excel('file_sources.xls',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will read the URLs, and store the content of them in a series of Pandas DataFrames from the Excel Files. I will hold them in a list of Pandas Data Frames called **files**. This procedure will take some time (I put a small progress bar). If any of the files has a problem (e.g. couldn't be downloaded or opened), this procedure will raise an exception. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdb4e2994aa440090320bb48836c1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "URLs downloaded:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with report from DEC of the year 2017\n",
      "Unsupported format, or corrupt file: Expected BOF record; found b'REFERENC'\n",
      "Total number of records 185909\n",
      "Downloaded files 44\n"
     ]
    }
   ],
   "source": [
    "num_files = len(sources_df)\n",
    "num_records = 0\n",
    "files = []\n",
    "for idx,source in tqdm(sources_df.iterrows(),\n",
    "                       total=num_files,\n",
    "                       desc='URLs downloaded'):\n",
    "    mes = source['Mes']\n",
    "    ano = source['Año']\n",
    "    url_source = str(source['Link'])\n",
    "    try:\n",
    "        data_file = pd.read_excel(url_source)\n",
    "        files.append(data_file)\n",
    "        num_records += int(len(data_file))\n",
    "    except Exception as e:\n",
    "        print('Problem with report from', mes,'of the year',ano)\n",
    "        print(e)\n",
    "#at the end print the number of records found and the number of files obtained\n",
    "print('Total number of records',num_records)\n",
    "#update the number of files if any should fail\n",
    "num_files = len(files)\n",
    "print('Downloaded files',num_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second task: Understanding the structure of the files \n",
    "\n",
    "According to the output we read succesfully 44 out of 45 files (only December 2017 was corrupt), and stored them as individual DataFrames. Moreover, we are dealing with a dataset of 185909 credit card payments distributed in montly reports starting in April 2014 all the way up to January 2018, with two exceptions: there is no record of transactions in April 2015, and the file for December 2017. \n",
    "\n",
    "Now, I wish to see the variables (columns) present in each file, and give myself an idea about what is contained in them. Moreover, I am interested in seeing if there are common variables in each one. I will store all variables (column names) found int the files in a set called **vars_found**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b4a408637d4ca586204760b0771a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BILLING CUR CODE.1\n",
      "ORIGINAL GROSS AMT\n",
      "BILLING CUR CODE\n",
      "Directorates\n",
      "TRANS CAC DESC 1\n",
      "Directorate\n",
      "TRANS CAC CODE 3\n",
      "Directorate \n",
      "TRANS CAC CODE 2\n",
      "TRANS CAC CODE 1\n",
      "BILLING GROSS AMT\n",
      "MERCHANT NAME\n",
      "TRANS DATE\n",
      "ORIGINAL CUR\n",
      "TRANS TAX AMT\n",
      "CARD NUMBER\n",
      "Unnamed: 10\n",
      "TRANS CAC DESC 2\n",
      "TRANS VAT DESC\n"
     ]
    }
   ],
   "source": [
    "vars_found = set()\n",
    "for file in tqdm(files):\n",
    "    vars_found = vars_found.union(set(file.columns))\n",
    "for var in vars_found:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that since these variables were obtained by *adding* the variables found in each file, it is only natural that they show in at least one of the files. In order to detect which variables are *global* (i.e. present in each file) we will measure variables' *prevalence* among the files:\n",
    "\n",
    "$$prevalence = \\frac{\\# \\text{files in which it shows}}{\\#\\text{number of files}}\\times 100\\%$$\n",
    "\n",
    "this prevalence will give us an idea of what *global variables* are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>num_files</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BILLING CUR CODE.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ORIGINAL GROSS AMT</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BILLING CUR CODE</td>\n",
       "      <td>21</td>\n",
       "      <td>47.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Directorates</td>\n",
       "      <td>2</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TRANS CAC DESC 1</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Directorate</td>\n",
       "      <td>40</td>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>TRANS CAC CODE 3</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Directorate</td>\n",
       "      <td>1</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TRANS CAC CODE 2</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>TRANS CAC CODE 1</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>BILLING GROSS AMT</td>\n",
       "      <td>12</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>MERCHANT NAME</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>TRANS DATE</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ORIGINAL CUR</td>\n",
       "      <td>12</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>TRANS TAX AMT</td>\n",
       "      <td>1</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>CARD NUMBER</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Unnamed: 10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>TRANS CAC DESC 2</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>TRANS VAT DESC</td>\n",
       "      <td>44</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   var  num_files  prevalence\n",
       "0   BILLING CUR CODE.1          1    2.272727\n",
       "1   ORIGINAL GROSS AMT         44  100.000000\n",
       "2     BILLING CUR CODE         21   47.727273\n",
       "3         Directorates          2    4.545455\n",
       "4     TRANS CAC DESC 1         44  100.000000\n",
       "5          Directorate         40   90.909091\n",
       "6     TRANS CAC CODE 3         44  100.000000\n",
       "7         Directorate           1    2.272727\n",
       "8     TRANS CAC CODE 2         44  100.000000\n",
       "9     TRANS CAC CODE 1         44  100.000000\n",
       "10   BILLING GROSS AMT         12   27.272727\n",
       "11       MERCHANT NAME         44  100.000000\n",
       "12          TRANS DATE         44  100.000000\n",
       "13        ORIGINAL CUR         12   27.272727\n",
       "14       TRANS TAX AMT          1    2.272727\n",
       "15         CARD NUMBER         44  100.000000\n",
       "16         Unnamed: 10          1    2.272727\n",
       "17    TRANS CAC DESC 2         44  100.000000\n",
       "18      TRANS VAT DESC         44  100.000000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the prevalence dictionary as a dictionary by comprehension\n",
    "var_prevalence = {var:0 for var in vars_found}\n",
    "#now we traverse the list of DataFrames\n",
    "for file in files:\n",
    "    file_vars = list(file.columns)\n",
    "    for var in file_vars:\n",
    "            var_prevalence[var] +=1\n",
    "#now we will create a variables dataframe\n",
    "var_df = pd.DataFrame(columns=['var','total'])\n",
    "var_df = var_df.from_dict(var_prevalence,orient='index')\n",
    "#now we tailor the DataFrame\n",
    "var_df = var_df.reset_index()\n",
    "var_df = var_df.rename({'index':'var',0:'num_files'},axis=1)\n",
    "var_df['prevalence'] = 100.0*var_df['num_files']/float(num_files)\n",
    "#now we see the dataframe\n",
    "var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have multiple fields with similar names. For example, notice that the *Directorate* field comes with variations, occupying 43 out of the 44 files. Since the prevalence is not 100%, we will *discard* this variable for the moment. Now I wish to isolate all global variables (i.e. variables with a  100% prevalence), I will store these in a list called *global_vars*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate global variables filtering by 100% prevalence\n",
    "var_df.loc[var_df['prevalence'] == 100.0]\n",
    "#store these variables in a list. \n",
    "global_vars = list(var_df.loc[var_df['prevalence'] == 100.0]['var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Task: Create a single unified Dataset from Global Variables\n",
    "\n",
    "Now that I have isolated these global variables, I wish to create a single DataFrame from it, so that I can perform analysis on it in another Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab43aaeea1040199b841920bd2e8ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records 185909\n",
      "number of variables 10\n"
     ]
    }
   ],
   "source": [
    "#create global dataset\n",
    "global_dataset = pd.DataFrame(columns=global_vars)\n",
    "#append the transactions from each monthly report\n",
    "for file in tqdm(files):\n",
    "    sub_data = file[global_vars]\n",
    "    global_dataset = global_dataset.append(sub_data,ignore_index=True)\n",
    "#I will create a unified transaction id using the index\n",
    "global_dataset = global_dataset.reset_index()\n",
    "#rename the former index as transac_id\n",
    "global_dataset.rename({'index':'transac_id'})\n",
    "print('number of records',len(global_dataset))\n",
    "print('number of variables',len(global_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can check a little bit of this dataset, to get the feeling of what these global variables describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ORIGINAL GROSS AMT</th>\n",
       "      <th>TRANS CAC DESC 1</th>\n",
       "      <th>TRANS CAC CODE 3</th>\n",
       "      <th>TRANS CAC CODE 2</th>\n",
       "      <th>TRANS CAC CODE 1</th>\n",
       "      <th>MERCHANT NAME</th>\n",
       "      <th>TRANS DATE</th>\n",
       "      <th>CARD NUMBER</th>\n",
       "      <th>TRANS CAC DESC 2</th>\n",
       "      <th>TRANS VAT DESC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>66254</td>\n",
       "      <td>66254</td>\n",
       "      <td>6.20</td>\n",
       "      <td>Vehicle OthrunCosts</td>\n",
       "      <td>A00</td>\n",
       "      <td>RLBMC</td>\n",
       "      <td>K080</td>\n",
       "      <td>park mobile</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>************2909</td>\n",
       "      <td>Technical Unit</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58201</td>\n",
       "      <td>58201</td>\n",
       "      <td>19.52</td>\n",
       "      <td>Supplies &amp; Sev Mic</td>\n",
       "      <td>A00</td>\n",
       "      <td>REAEC</td>\n",
       "      <td>MC70</td>\n",
       "      <td>leaway s/stn</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>************3866</td>\n",
       "      <td>Gossey Lane Junior &amp; Infant</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100955</td>\n",
       "      <td>100955</td>\n",
       "      <td>23.98</td>\n",
       "      <td>Equip Operational</td>\n",
       "      <td>A00</td>\n",
       "      <td>RUAG1</td>\n",
       "      <td>L100</td>\n",
       "      <td>amazon uk marketplace</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>************0407</td>\n",
       "      <td>Yardley Crematorium General</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178904</td>\n",
       "      <td>178904</td>\n",
       "      <td>775.00</td>\n",
       "      <td>Promotions/Marketing</td>\n",
       "      <td>A00</td>\n",
       "      <td>RP005</td>\n",
       "      <td>L5H0</td>\n",
       "      <td>www.onlinecalendarsho</td>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>************3475</td>\n",
       "      <td>City Centre</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121669</td>\n",
       "      <td>121669</td>\n",
       "      <td>43.60</td>\n",
       "      <td>Purchases Food</td>\n",
       "      <td>A00</td>\n",
       "      <td>REAAB</td>\n",
       "      <td>L220</td>\n",
       "      <td>greggs - s0542</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>************7065</td>\n",
       "      <td>The City of Birmingham School</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158918</td>\n",
       "      <td>158918</td>\n",
       "      <td>6.22</td>\n",
       "      <td>Water Services</td>\n",
       "      <td>A00</td>\n",
       "      <td>RDP7G</td>\n",
       "      <td>J280</td>\n",
       "      <td>www.stwater.co.uk</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>************3929</td>\n",
       "      <td>Gazzette Building 168 Corpn St</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72120</td>\n",
       "      <td>72120</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Equip Operational</td>\n",
       "      <td>A00</td>\n",
       "      <td>REAHH</td>\n",
       "      <td>L100</td>\n",
       "      <td>www.theworks.co.uk</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>************9823</td>\n",
       "      <td>Moseley CE Junior &amp; Infant</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101274</td>\n",
       "      <td>101274</td>\n",
       "      <td>1184.90</td>\n",
       "      <td>Other Third Parties</td>\n",
       "      <td>A00</td>\n",
       "      <td>RJADC</td>\n",
       "      <td>N060</td>\n",
       "      <td>travelodge website</td>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>************6316</td>\n",
       "      <td>Homeless Private Sector Accom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83199</td>\n",
       "      <td>83199</td>\n",
       "      <td>34.70</td>\n",
       "      <td>Equip Other</td>\n",
       "      <td>A00</td>\n",
       "      <td>REAJF</td>\n",
       "      <td>L120</td>\n",
       "      <td>amazon uk retail</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>************7538</td>\n",
       "      <td>Paget Primary  (NC)</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63287</td>\n",
       "      <td>63287</td>\n",
       "      <td>44.00</td>\n",
       "      <td>Equip Operational</td>\n",
       "      <td>A00</td>\n",
       "      <td>REAXZ</td>\n",
       "      <td>L100</td>\n",
       "      <td>tesco direct</td>\n",
       "      <td>2015-09-24</td>\n",
       "      <td>************3989</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  ORIGINAL GROSS AMT      TRANS CAC DESC 1 TRANS CAC CODE 3  \\\n",
       "66254    66254                6.20   Vehicle OthrunCosts              A00   \n",
       "58201    58201               19.52    Supplies & Sev Mic              A00   \n",
       "100955  100955               23.98     Equip Operational              A00   \n",
       "178904  178904              775.00  Promotions/Marketing              A00   \n",
       "121669  121669               43.60        Purchases Food              A00   \n",
       "158918  158918                6.22        Water Services              A00   \n",
       "72120    72120               50.00     Equip Operational              A00   \n",
       "101274  101274             1184.90   Other Third Parties              A00   \n",
       "83199    83199               34.70           Equip Other              A00   \n",
       "63287    63287               44.00     Equip Operational              A00   \n",
       "\n",
       "       TRANS CAC CODE 2 TRANS CAC CODE 1          MERCHANT NAME TRANS DATE  \\\n",
       "66254             RLBMC             K080            park mobile 2015-09-14   \n",
       "58201             REAEC             MC70           leaway s/stn 2015-07-15   \n",
       "100955            RUAG1             L100  amazon uk marketplace 2016-05-27   \n",
       "178904            RP005             L5H0  www.onlinecalendarsho 2017-11-13   \n",
       "121669            REAAB             L220         greggs - s0542 2016-10-19   \n",
       "158918            RDP7G             J280      www.stwater.co.uk 2017-07-24   \n",
       "72120             REAHH             L100     www.theworks.co.uk 2015-11-10   \n",
       "101274            RJADC             N060     travelodge website 2016-06-17   \n",
       "83199             REAJF             L120       amazon uk retail 2016-01-26   \n",
       "63287             REAXZ             L100           tesco direct 2015-09-24   \n",
       "\n",
       "             CARD NUMBER                TRANS CAC DESC 2 TRANS VAT DESC  \n",
       "66254   ************2909                  Technical Unit             VR  \n",
       "58201   ************3866     Gossey Lane Junior & Infant             VR  \n",
       "100955  ************0407     Yardley Crematorium General             VZ  \n",
       "178904  ************3475                     City Centre             VZ  \n",
       "121669  ************7065   The City of Birmingham School             VZ  \n",
       "158918  ************3929  Gazzette Building 168 Corpn St             VZ  \n",
       "72120   ************9823      Moseley CE Junior & Infant             VZ  \n",
       "101274  ************6316   Homeless Private Sector Accom            NaN  \n",
       "83199   ************7538             Paget Primary  (NC)             VZ  \n",
       "63287   ************3989                        Hamilton             VZ  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dataset.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Task: Data cleanup\n",
    "\n",
    "From this small sample of the Dataset, we can infer that the variables stand for the following:\n",
    "\n",
    "- **ORIGINAL GROSS AMT** the amount paid in the transaction\n",
    "- **TRANS CAC DESC 1** A description of the transaction's purpose\n",
    "- **MERCHANT NAME** The name of the store/facility that is the recipient of the transaction\n",
    "- **TRANS DATE** the date on which the transaction occured\n",
    "- **CARD NUMBER** the number of the card used to pay \n",
    "- **TRANS CAC DESC 2** A more detailed description of the store/facility where the transaction ocurred\n",
    "- **TRANS CAC CODE 1,2,3** Internal codes to describe the transaction. \n",
    "- **TRANS VAT DESC** another code describing the transaction. \n",
    "\n",
    "Let's simplify the names and remove spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>amount</th>\n",
       "      <th>cac_desc_1</th>\n",
       "      <th>cac_code_3</th>\n",
       "      <th>cac_code_2</th>\n",
       "      <th>cac_code_1</th>\n",
       "      <th>merchant</th>\n",
       "      <th>date</th>\n",
       "      <th>card</th>\n",
       "      <th>cac_desc_2</th>\n",
       "      <th>vat_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>136078</td>\n",
       "      <td>136078</td>\n",
       "      <td>40.24</td>\n",
       "      <td>Vehicle Fuel</td>\n",
       "      <td>A00</td>\n",
       "      <td>RTG15</td>\n",
       "      <td>K020</td>\n",
       "      <td>tesco pfs 4203</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>************0479</td>\n",
       "      <td>Enforcement Team</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40329</td>\n",
       "      <td>40329</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Vehicle OthrunCosts</td>\n",
       "      <td>A00</td>\n",
       "      <td>RV05X</td>\n",
       "      <td>K080</td>\n",
       "      <td>park mobile</td>\n",
       "      <td>2015-02-12</td>\n",
       "      <td>************8665</td>\n",
       "      <td>Admin Management Support</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77427</td>\n",
       "      <td>77427</td>\n",
       "      <td>13.00</td>\n",
       "      <td>Equip Operational</td>\n",
       "      <td>A00</td>\n",
       "      <td>REACF</td>\n",
       "      <td>L100</td>\n",
       "      <td>amazon uk marketplace</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>************2231</td>\n",
       "      <td>Cherry Orchard Junior &amp; Infant</td>\n",
       "      <td>VZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154988</td>\n",
       "      <td>154988</td>\n",
       "      <td>250.00</td>\n",
       "      <td>Bank &amp; Goro ChgsS</td>\n",
       "      <td>A00</td>\n",
       "      <td>REAXL</td>\n",
       "      <td>L540</td>\n",
       "      <td>home bargains</td>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>************5190</td>\n",
       "      <td>Baskerville</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72049</td>\n",
       "      <td>72049</td>\n",
       "      <td>69.80</td>\n",
       "      <td>Vehicle Fuel</td>\n",
       "      <td>A00</td>\n",
       "      <td>RV024</td>\n",
       "      <td>K020</td>\n",
       "      <td>morrisons petrol</td>\n",
       "      <td>2015-11-06</td>\n",
       "      <td>************3417</td>\n",
       "      <td>Leach Green Lane CH</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  amount           cac_desc_1 cac_code_3 cac_code_2 cac_code_1  \\\n",
       "136078  136078   40.24         Vehicle Fuel        A00      RTG15       K020   \n",
       "40329    40329    3.10  Vehicle OthrunCosts        A00      RV05X       K080   \n",
       "77427    77427   13.00    Equip Operational        A00      REACF       L100   \n",
       "154988  154988  250.00    Bank & Goro ChgsS        A00      REAXL       L540   \n",
       "72049    72049   69.80         Vehicle Fuel        A00      RV024       K020   \n",
       "\n",
       "                     merchant       date              card  \\\n",
       "136078         tesco pfs 4203 2017-02-01  ************0479   \n",
       "40329             park mobile 2015-02-12  ************8665   \n",
       "77427   amazon uk marketplace 2015-12-15  ************2231   \n",
       "154988          home bargains 2017-07-02  ************5190   \n",
       "72049        morrisons petrol 2015-11-06  ************3417   \n",
       "\n",
       "                            cac_desc_2 vat_desc  \n",
       "136078                Enforcement Team       VR  \n",
       "40329         Admin Management Support       VZ  \n",
       "77427   Cherry Orchard Junior & Infant       VZ  \n",
       "154988                     Baskerville       VR  \n",
       "72049              Leach Green Lane CH       VR  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dataset.rename({'ORIGINAL GROSS AMT':'amount', \n",
    "                     'TRANS CAC DESC 1':'cac_desc_1', \n",
    "                     'TRANS CAC CODE 3':'cac_code_3',\n",
    "                     'TRANS CAC CODE 2':'cac_code_2', \n",
    "                     'TRANS CAC CODE 1':'cac_code_1', \n",
    "                     'MERCHANT NAME':'merchant', \n",
    "                     'TRANS DATE':'date',\n",
    "                     'CARD NUMBER':'card', \n",
    "                     'TRANS CAC DESC 2':'cac_desc_2', \n",
    "                     'TRANS VAT DESC':'vat_desc'},\n",
    "                      axis=1,\n",
    "                     inplace=True)\n",
    "#Let's see how it looks. \n",
    "global_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that there is a combination of categorical and numerical variables including one date-time field. Let's see the types registered by Pandas to see if we need to cast any variable for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                  int64\n",
       "amount               float64\n",
       "cac_desc_1            object\n",
       "cac_code_3            object\n",
       "cac_code_2            object\n",
       "cac_code_1            object\n",
       "merchant              object\n",
       "date          datetime64[ns]\n",
       "card                  object\n",
       "cac_desc_2            object\n",
       "vat_desc              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the *card* field contains only the four last digits of the card, it doesn't make much sense to keep the trail of asterisks. Let's remove it using a lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>amount</th>\n",
       "      <th>cac_desc_1</th>\n",
       "      <th>cac_code_3</th>\n",
       "      <th>cac_code_2</th>\n",
       "      <th>cac_code_1</th>\n",
       "      <th>merchant</th>\n",
       "      <th>date</th>\n",
       "      <th>card</th>\n",
       "      <th>cac_desc_2</th>\n",
       "      <th>vat_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.32</td>\n",
       "      <td>Vehicle Fuel</td>\n",
       "      <td>A00</td>\n",
       "      <td>RV12N</td>\n",
       "      <td>K020</td>\n",
       "      <td>shell kings 587</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>5770</td>\n",
       "      <td>African-Caribbean DC</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.82</td>\n",
       "      <td>Vehicle Fuel</td>\n",
       "      <td>A00</td>\n",
       "      <td>RV12N</td>\n",
       "      <td>K020</td>\n",
       "      <td>shell kings 587</td>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>5770</td>\n",
       "      <td>African-Caribbean DC</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41.35</td>\n",
       "      <td>Vehicle Fuel</td>\n",
       "      <td>A00</td>\n",
       "      <td>RV11Y</td>\n",
       "      <td>K020</td>\n",
       "      <td>tesco pfs 2484</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>8738</td>\n",
       "      <td>Marsh Lane Dce, 79, B23</td>\n",
       "      <td>VR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  amount    cac_desc_1 cac_code_3 cac_code_2 cac_code_1  \\\n",
       "0      0   52.32  Vehicle Fuel        A00      RV12N       K020   \n",
       "1      1   65.82  Vehicle Fuel        A00      RV12N       K020   \n",
       "2      2   41.35  Vehicle Fuel        A00      RV11Y       K020   \n",
       "\n",
       "          merchant       date  card               cac_desc_2 vat_desc  \n",
       "0  shell kings 587 2014-04-29  5770     African-Caribbean DC       VR  \n",
       "1  shell kings 587 2014-04-04  5770     African-Caribbean DC       VR  \n",
       "2   tesco pfs 2484 2014-04-07  8738  Marsh Lane Dce, 79, B23       VR  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dataset['card'] = global_dataset['card'].apply(lambda x: str(x)[-4:])\n",
    "global_dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will only check for Nulls and Nans and remove them. In the analysis part I will determine if there are *strange* transactions upon checking expected values and whatnot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are null records\n",
      "----------------------\n",
      "There are 10822\n",
      "index            0\n",
      "amount           1\n",
      "cac_desc_1     105\n",
      "cac_code_3     293\n",
      "cac_code_2     236\n",
      "cac_code_1     105\n",
      "merchant         1\n",
      "date             1\n",
      "card             0\n",
      "cac_desc_2     236\n",
      "vat_desc      9844\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if global_dataset.isnull().values.any():\n",
    "    print('There are null records')\n",
    "    print('----------------------')\n",
    "    num_null_records = global_dataset.isnull().sum().sum()\n",
    "    print('There are', num_null_records)\n",
    "    print(global_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the most nulls are in the *vat_desc* column (almost 10 thousand), they are too many to simply drop. However, I will drop the records where the date or merchant are null, alongside with the records missing any CAC value (CAC code and cac desc). There is only one transaction missing it's value. I will drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after cleanup 185480\n"
     ]
    }
   ],
   "source": [
    "global_dataset = global_dataset.dropna(subset=['cac_desc_1',\n",
    "                                               'cac_desc_2',\n",
    "                                               'cac_code_1',\n",
    "                                               'cac_code_2',\n",
    "                                               'cac_code_3',\n",
    "                                               'date',\n",
    "                                               'amount'])\n",
    "print('Number of records after cleanup',len(global_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this cleanup we went from 185'909 records to 185'480 records. This is just a decrease in 429 records, that accounts for just 0.23% of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Task: Save the Dataset to a CSV File. \n",
    "\n",
    "Now, we will save this dataset in a single csv file for analysis, that we will perform in another Jupyter Notebook. Since I am latino, I use the semi-colon as separator (so I can open this also in Excel), because I use the european number format (with a decimal comma, instead of a decimal point). I will mind this when opening the file in the next Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dataset.to_csv('credit_card_transactions.csv',\n",
    "                      sep=';', #I will use the semi colon\n",
    "                      decimal=',', #I will use the european decimal comma instead of the decimal point\n",
    "                      index=False) #I will drop the index from the DataFrame. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
